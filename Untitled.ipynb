{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "157de37a-5da0-46ef-85ae-97d6265ce63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed. Cleaned data saved to output-removed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = 'now.csv'  \n",
    "output_file = 'output-removed.csv'  \n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "df_cleaned.to_csv(output_file, index=False)\n",
    "\n",
    "print(f'Duplicates removed. Cleaned data saved to {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422acc0c-4771-47b2-a760-ebcacfb1357f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.0637\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 136, does not match size of target_names, 404. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m accuracy_logistic \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred_logistic)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_logistic\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred_logistic, target_names\u001b[38;5;241m=\u001b[39mlabel_encoder\u001b[38;5;241m.\u001b[39mclasses_))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2332\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2326\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2327\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2328\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2329\u001b[0m             )\n\u001b[0;32m   2330\u001b[0m         )\n\u001b[0;32m   2331\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2332\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2334\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2336\u001b[0m         )\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2338\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 136, does not match size of target_names, 404. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "data = pd.read_csv('output-removed.csv')\n",
    "\n",
    "# Convert \"Yes\"/\"No\" to binary (1/0)\n",
    "data.replace({\"Yes\": 1, \"No\": 0}, inplace=True)\n",
    "\n",
    "# Encode the job titles as numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['Job Title'] = label_encoder.fit_transform(data['Job Title'])\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = data.drop(columns='Job Title')\n",
    "y = data['Job Title']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter=2000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logistic:.4f}\")\n",
    "print(classification_report(y_test, y_pred_logistic, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a81a68b-a3da-4920-a434-314d9ae667c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.0637\n",
      "                                              precision    recall  f1-score   support\n",
      "\n",
      "                                 AI Engineer       0.12      0.12      0.12        24\n",
      "                       AI Research Scientist       0.00      0.00      0.00         1\n",
      "                               AI Researcher       0.00      0.00      0.00         0\n",
      "                  AI-Powered Product Manager       0.00      0.00      0.00         1\n",
      "                  API Integration Specialist       0.00      0.00      0.00         0\n",
      "                             AR/VR Developer       0.00      0.00      0.00         0\n",
      "                          Algorithm Engineer       0.00      0.00      0.00         0\n",
      "                       Application Developer       0.00      0.00      0.00         0\n",
      "            Application Performance Engineer       0.00      0.00      0.00         0\n",
      "               Application Security Engineer       0.00      0.00      0.00         0\n",
      "                 Application Support Analyst       0.00      0.00      0.00         0\n",
      "                 Application Support Manager       0.00      0.00      0.00         0\n",
      "            Artificial Intelligence Engineer       0.00      0.00      0.00         1\n",
      "          Artificial Intelligence Researcher       0.00      0.00      0.00         0\n",
      "                   Audio Processing Engineer       0.00      0.00      0.00         0\n",
      "            Augmented Reality (AR) Developer       0.00      0.00      0.00         1\n",
      "                 Augmented Reality Developer       0.00      0.00      0.00         0\n",
      "                         Automation Engineer       0.00      0.00      0.00         0\n",
      "                    Automation Test Engineer       0.00      0.00      0.00         0\n",
      "                 Autonomous Systems Engineer       0.00      0.00      0.00         0\n",
      "                                BI Developer       0.00      0.00      0.00         0\n",
      "                          Back-End Developer       0.00      0.00      0.00         0\n",
      "                           Backend Developer       0.18      0.18      0.18        11\n",
      "                            Backend Engineer       0.00      0.00      0.00         0\n",
      "                          Big Data Architect       0.00      0.00      0.00         0\n",
      "                           Big Data Engineer       0.00      0.00      0.00         0\n",
      "               Bioinformatics Data Scientist       0.00      0.00      0.00         0\n",
      "                    Bioinformatics Scientist       0.00      0.00      0.00         1\n",
      "           Bioinformatics Software Developer       0.00      0.00      0.00         0\n",
      "                        Blockchain Architect       0.00      0.00      0.00         0\n",
      "                        Blockchain Developer       0.00      0.00      0.00         0\n",
      "                            Business Analyst       0.00      0.00      0.00         0\n",
      "               Business Intelligence Analyst       0.00      0.00      0.00         1\n",
      "             Business Intelligence Developer       0.00      0.00      0.00         0\n",
      "                           CRM Administrator       0.00      0.00      0.00         0\n",
      "                               CRM Developer       0.00      0.00      0.00         1\n",
      "                Change Management Specialist       0.00      0.00      0.00         0\n",
      "                    Chief Data Officer (CDO)       0.00      0.00      0.00         0\n",
      "             Chief Information Officer (CIO)       0.00      0.00      0.00         1\n",
      "   Chief Information Security Officer (CISO)       0.00      0.00      0.00         0\n",
      "              Chief Technology Officer (CTO)       0.00      0.00      0.00         1\n",
      "                 Cloud Application Developer       0.00      0.00      0.00         0\n",
      "                             Cloud Architect       0.00      0.00      0.00         0\n",
      "                   Cloud Automation Engineer       0.00      0.00      0.00         0\n",
      "                       Cloud DevOps Engineer       0.00      0.00      0.00         1\n",
      "                              Cloud Engineer       0.00      0.00      0.00        10\n",
      "               Cloud Infrastructure Engineer       0.00      0.00      0.00         1\n",
      "                  Cloud Migration Specialist       0.00      0.00      0.00         0\n",
      "                       Cloud Native Engineer       0.00      0.00      0.00         0\n",
      "                      Cloud Network Engineer       0.00      0.00      0.00         0\n",
      "                   Cloud Operations Engineer       0.00      0.00      0.00         0\n",
      "                     Cloud Platform Engineer       0.00      0.00      0.00         1\n",
      "                    Cloud Security Architect       0.00      0.00      0.00         1\n",
      "                     Cloud Security Engineer       0.00      0.00      0.00         1\n",
      "                   Cloud Solutions Architect       0.00      0.00      0.00         1\n",
      "                    Cloud Solutions Engineer       0.00      0.00      0.00         0\n",
      "                          Compliance Analyst       0.00      0.00      0.00         0\n",
      "                          Compliance Officer       0.00      0.00      0.00         0\n",
      "                       Computational Chemist       0.00      0.00      0.00         0\n",
      "                Computational Neuroscientist       0.00      0.00      0.00         0\n",
      "                     Computational Scientist       0.00      0.00      0.00         0\n",
      "                           Computer Engineer       0.00      0.00      0.00         0\n",
      "                    Computer Vision Engineer       0.00      0.00      0.00         0\n",
      "                 Containerization Specialist       0.00      0.00      0.00         0\n",
      "                               Cryptographer       0.00      0.00      0.00         0\n",
      "                       Cyber Defense Analyst       0.00      0.00      0.00         0\n",
      "                       Cybersecurity Analyst       0.12      0.11      0.12        18\n",
      "                     Cybersecurity Architect       0.00      0.00      0.00         1\n",
      "                    Cybersecurity Consultant       0.00      0.00      0.00         1\n",
      "                      Cybersecurity Engineer       0.00      0.00      0.00         0\n",
      "                    Cybersecurity Specialist       0.00      0.00      0.00         0\n",
      "                                Data Analyst       0.00      0.00      0.00         0\n",
      "                   Data Analytics Consultant       0.00      0.00      0.00         0\n",
      "                              Data Architect       0.00      0.00      0.00         0\n",
      "              Data Center Operations Manager       0.00      0.00      0.00         0\n",
      "                      Data Center Technician       0.00      0.00      0.00         1\n",
      "                               Data Engineer       0.00      0.00      0.00         0\n",
      "                  Data Governance Specialist       0.00      0.00      0.00         0\n",
      "                 Data Integration Specialist       0.00      0.00      0.00         0\n",
      "                   Data Migration Specialist       0.00      0.00      0.00         0\n",
      "                  Data Operations Specialist       0.00      0.00      0.00         0\n",
      "                        Data Privacy Officer       0.00      0.00      0.00         1\n",
      "                  Data Protection Specialist       0.00      0.00      0.00         0\n",
      "                        Data Quality Analyst       0.00      0.00      0.00         0\n",
      "                           Data Risk Manager       0.00      0.00      0.00         1\n",
      "                              Data Scientist       0.00      0.00      0.00        21\n",
      "                      Data Scientist Manager       0.00      0.00      0.00         1\n",
      "               Data Visualization Specialist       0.00      0.00      0.00         1\n",
      "                    Data Warehouse Architect       0.00      0.00      0.00         1\n",
      "                     Data Warehouse Engineer       0.00      0.00      0.00         0\n",
      "                            DataOps Engineer       0.00      0.00      0.00         0\n",
      "                      Database Administrator       0.04      0.06      0.05        17\n",
      "                          Database Developer       0.00      0.00      0.00         0\n",
      "                           Database Engineer       0.00      0.00      0.00         1\n",
      "                      Deep Learning Engineer       0.00      0.00      0.00         0\n",
      "                    Deep Learning Researcher       0.00      0.00      0.00         0\n",
      "                            DevOps Architect       0.00      0.00      0.00         0\n",
      "                           DevOps Consultant       0.00      0.00      0.00         0\n",
      "                             DevOps Engineer       0.09      0.11      0.10        18\n",
      "                           DevOps Specialist       0.00      0.00      0.00         0\n",
      "                          DevSecOps Engineer       0.00      0.00      0.00         1\n",
      "                   Digital Forensics Analyst       0.00      0.00      0.00         0\n",
      "              Digital Forensics Investigator       0.00      0.00      0.00         1\n",
      "                     Digital Product Manager       0.00      0.00      0.00         0\n",
      "                 Digital Solutions Architect       0.00      0.00      0.00         0\n",
      "                    Digital Systems Engineer       0.00      0.00      0.00         0\n",
      "           Digital Transformation Consultant       0.00      0.00      0.00         0\n",
      "             Digital Transformation Engineer       0.00      0.00      0.00         0\n",
      "                       Digital Twin Engineer       0.00      0.00      0.00         0\n",
      "                   Disaster Recovery Manager       0.00      0.00      0.00         0\n",
      "                Disaster Recovery Specialist       0.00      0.00      0.00         0\n",
      "                        E-commerce Developer       0.00      0.00      0.00         0\n",
      "                               ETL Developer       0.00      0.00      0.00         0\n",
      "                     Edge Computing Engineer       0.00      0.00      0.00         0\n",
      "                 Embedded Software Developer       0.00      0.00      0.00         0\n",
      "                  Embedded Software Engineer       0.00      0.00      0.00         0\n",
      "                  Embedded Systems Architect       0.00      0.00      0.00         0\n",
      "                   Embedded Systems Engineer       0.00      0.00      0.00         1\n",
      "                        Enterprise Architect       0.00      0.00      0.00         0\n",
      "Enterprise Resource Planning (ERP) Developer       0.00      0.00      0.00         0\n",
      "                              Ethical Hacker       0.00      0.00      0.00         0\n",
      "                               FPGA Engineer       0.00      0.00      0.00         0\n",
      "                          Firmware Developer       0.00      0.00      0.00         0\n",
      "                           Firmware Engineer       0.00      0.00      0.00         1\n",
      "                       Forensic Data Analyst       0.00      0.00      0.00         0\n",
      "                         Front-End Developer       0.00      0.00      0.00         0\n",
      "                          Frontend Developer       0.21      0.32      0.26        19\n",
      "                        Full Stack Developer       0.03      0.08      0.04        12\n",
      "                        Full-Stack Developer       0.00      0.00      0.00         0\n",
      "                         Full-Stack Engineer       0.00      0.00      0.00         0\n",
      "                       Functional Consultant       0.00      0.00      0.00         0\n",
      "                               Game Designer       0.00      0.00      0.00         0\n",
      "                              Game Developer       0.00      0.00      0.00         0\n",
      "                       Game Engine Developer       0.00      0.00      0.00         1\n",
      "                     Genomics Data Scientist       0.00      0.00      0.00         0\n",
      "                           Hardware Engineer       0.00      0.00      0.00         0\n",
      "                  Hardware Security Engineer       0.00      0.00      0.00         1\n",
      "       High Performance Computing Specialist       0.00      0.00      0.00         1\n",
      "         High-Performance Computing Engineer       0.00      0.00      0.00         0\n",
      "                          IT Account Manager       0.00      0.00      0.00         0\n",
      "              IT Asset Management Specialist       0.00      0.00      0.00         1\n",
      "                            IT Asset Manager       0.00      0.00      0.00         0\n",
      "                            IT Audit Manager       0.00      0.00      0.00         0\n",
      "                                  IT Auditor       0.00      0.00      0.00         0\n",
      "                     IT Automation Architect       0.00      0.00      0.00         0\n",
      "                      IT Automation Engineer       0.00      0.00      0.00         0\n",
      "                           IT Budget Analyst       0.00      0.00      0.00         0\n",
      "                         IT Business Analyst       0.00      0.00      0.00         0\n",
      "            IT Business Intelligence Analyst       0.00      0.00      0.00         0\n",
      "                         IT Business Partner       0.00      0.00      0.00         0\n",
      "                 IT Business Process Analyst       0.00      0.00      0.00         1\n",
      "                 IT Business Systems Analyst       0.00      0.00      0.00         0\n",
      "                         IT Capacity Planner       0.00      0.00      0.00         0\n",
      "                          IT Cloud Architect       0.00      0.00      0.00         0\n",
      "                         IT Cloud Consultant       0.00      0.00      0.00         0\n",
      "                           IT Cloud Engineer       0.00      0.00      0.00         0\n",
      "                            IT Cloud Manager       0.00      0.00      0.00         0\n",
      "                       IT Compliance Analyst       0.00      0.00      0.00         0\n",
      "                       IT Compliance Auditor       0.00      0.00      0.00         0\n",
      "                       IT Compliance Manager       0.00      0.00      0.00         0\n",
      "                    IT Compliance Specialist       0.00      0.00      0.00         1\n",
      "                    IT Configuration Analyst       0.00      0.00      0.00         0\n",
      "                   IT Configuration Engineer       0.00      0.00      0.00         0\n",
      "                    IT Configuration Manager       0.00      0.00      0.00         0\n",
      "                               IT Consultant       0.00      0.00      0.00         1\n",
      "                             IT Data Analyst       0.00      0.00      0.00         0\n",
      "                           IT Data Architect       0.00      0.00      0.00         0\n",
      "                    IT Data Center Architect       0.00      0.00      0.00         0\n",
      "                     IT Data Center Engineer       0.00      0.00      0.00         0\n",
      "                      IT Data Center Manager       0.00      0.00      0.00         0\n",
      "                            IT Data Engineer       0.00      0.00      0.00         1\n",
      "                           IT Data Scientist       0.00      0.00      0.00         0\n",
      "                   IT Database Administrator       0.00      0.00      0.00         1\n",
      "                       IT Database Developer       0.00      0.00      0.00         0\n",
      "                        IT Database Engineer       0.00      0.00      0.00         1\n",
      "                    IT Deployment Specialist       0.00      0.00      0.00         0\n",
      "                         IT DevOps Architect       0.00      0.00      0.00         0\n",
      "                          IT DevOps Engineer       0.00      0.00      0.00         0\n",
      "                              IT DevOps Lead       0.00      0.00      0.00         0\n",
      "                           IT DevOps Manager       0.00      0.00      0.00         0\n",
      "                        IT DevOps Specialist       0.00      0.00      0.00         1\n",
      "                                 IT Director       0.00      0.00      0.00         0\n",
      "                   IT Director of Operations       0.00      0.00      0.00         0\n",
      "             IT Disaster Recovery Specialist       0.00      0.00      0.00         0\n",
      "                        IT Financial Analyst       0.00      0.00      0.00         0\n",
      "                    IT Governance Specialist       0.00      0.00      0.00         0\n",
      "                    IT Help Desk Coordinator       0.00      0.00      0.00         0\n",
      "                           IT Help Desk Lead       0.00      0.00      0.00         0\n",
      "                        IT Help Desk Manager       0.00      0.00      0.00         0\n",
      "                     IT Help Desk Specialist       0.00      0.00      0.00         1\n",
      "                          IT ITIL Consultant       0.00      0.00      0.00         0\n",
      "                                IT ITIL Lead       0.00      0.00      0.00         0\n",
      "                             IT ITIL Manager       0.00      0.00      0.00         0\n",
      "                          IT ITIL Specialist       0.00      0.00      0.00         0\n",
      "                 IT Infrastructure Architect       0.00      0.00      0.00         0\n",
      "                IT Infrastructure Consultant       0.00      0.00      0.00         0\n",
      "                  IT Infrastructure Engineer       0.00      0.00      0.00         1\n",
      "                   IT Infrastructure Manager       0.00      0.00      0.00         2\n",
      "                     IT Integration Engineer       0.00      0.00      0.00         0\n",
      "                      IT Integration Manager       0.00      0.00      0.00         0\n",
      "                   IT Integration Specialist       0.00      0.00      0.00         0\n",
      "                                  IT Manager       0.00      0.00      0.00         0\n",
      "                    IT Network Administrator       0.00      0.00      0.00         1\n",
      "                        IT Network Architect       0.00      0.00      0.00         0\n",
      "                         IT Network Engineer       0.00      0.00      0.00         1\n",
      "                          IT Network Manager       0.00      0.00      0.00         1\n",
      "                       IT Operations Analyst       0.00      0.00      0.00         0\n",
      "                   IT Operations Coordinator       0.00      0.00      0.00         0\n",
      "                      IT Operations Director       0.00      0.00      0.00         0\n",
      "                          IT Operations Lead       0.00      0.00      0.00         1\n",
      "                       IT Operations Manager       0.00      0.00      0.00         1\n",
      "                      IT Performance Analyst       0.00      0.00      0.00         0\n",
      "                         IT Process Engineer       0.00      0.00      0.00         1\n",
      "                   IT Procurement Specialist       0.00      0.00      0.00         0\n",
      "                          IT Product Manager       0.00      0.00      0.00         0\n",
      "                         IT Program Director       0.00      0.00      0.00         0\n",
      "                          IT Program Manager       0.00      0.00      0.00         0\n",
      "                      IT Project Coordinator       0.00      0.00      0.00         0\n",
      "                          IT Project Manager       0.00      0.00      0.00         1\n",
      "                              IT QA Engineer       0.00      0.00      0.00         0\n",
      "                                  IT QA Lead       0.00      0.00      0.00         0\n",
      "                               IT QA Manager       0.00      0.00      0.00         0\n",
      "                         IT Release Engineer       0.00      0.00      0.00         0\n",
      "                          IT Release Manager       0.00      0.00      0.00         0\n",
      "                       IT Research Scientist       0.00      0.00      0.00         1\n",
      "                             IT Risk Analyst       0.00      0.00      0.00         1\n",
      "                             IT Risk Manager       0.00      0.00      0.00         0\n",
      "                         IT Security Analyst       0.00      0.00      0.00         0\n",
      "                       IT Security Architect       0.00      0.00      0.00         1\n",
      "                      IT Security Consultant       0.00      0.00      0.00         0\n",
      "                        IT Security Director       0.00      0.00      0.00         0\n",
      "                        IT Security Engineer       0.00      0.00      0.00         1\n",
      "                         IT Security Manager       0.00      0.00      0.00         1\n",
      " IT Security Operations Center (SOC) Analyst       0.00      0.00      0.00         0\n",
      "                    IT Service Delivery Lead       0.00      0.00      0.00         2\n",
      "                 IT Service Delivery Manager       0.00      0.00      0.00         1\n",
      "              IT Service Delivery Specialist       0.00      0.00      0.00         0\n",
      "                     IT Service Desk Analyst       0.00      0.00      0.00         0\n",
      "                        IT Service Desk Lead       0.00      0.00      0.00         1\n",
      "                     IT Service Desk Manager       0.00      0.00      0.00         0\n",
      "               IT Service Management Analyst       0.00      0.00      0.00         1\n",
      "            IT Service Management Specialist       0.00      0.00      0.00         0\n",
      "                          IT Service Manager       0.00      0.00      0.00         0\n",
      "                      IT Solutions Architect       0.00      0.00      0.00         1\n",
      "                       IT Solutions Engineer       0.00      0.00      0.00         0\n",
      "                      IT Strategy Consultant       0.00      0.00      0.00         0\n",
      "                            IT Strategy Lead       0.00      0.00      0.00         0\n",
      "                         IT Strategy Manager       0.00      0.00      0.00         0\n",
      "                          IT Support Manager       0.00      0.00      0.00         1\n",
      "                       IT Support Specialist       0.00      0.00      0.00         1\n",
      "                    IT Systems Administrator       0.00      0.00      0.00         0\n",
      "                          IT Systems Analyst       0.00      0.00      0.00         0\n",
      "                        IT Systems Architect       0.00      0.00      0.00         0\n",
      "                         IT Systems Engineer       0.00      0.00      0.00         0\n",
      "           IT Systems Integration Consultant       0.00      0.00      0.00         0\n",
      "             IT Systems Integration Engineer       0.00      0.00      0.00         1\n",
      "              IT Systems Integration Manager       0.00      0.00      0.00         0\n",
      "           IT Systems Integration Specialist       0.00      0.00      0.00         0\n",
      "                 IT Systems Support Engineer       0.00      0.00      0.00         0\n",
      "                     IT Systems Support Lead       0.00      0.00      0.00         0\n",
      "                  IT Systems Support Manager       0.00      0.00      0.00         0\n",
      "               IT Systems Support Specialist       0.00      0.00      0.00         0\n",
      "                IT Technical Project Manager       0.00      0.00      0.00         0\n",
      "                IT Technical Support Analyst       0.00      0.00      0.00         0\n",
      "               IT Technical Support Engineer       0.00      0.00      0.00         1\n",
      "                   IT Technical Support Lead       0.00      0.00      0.00         0\n",
      "                IT Technical Support Manager       0.00      0.00      0.00         1\n",
      "             IT Technical Support Specialist       0.00      0.00      0.00         1\n",
      "                      IT Training Specialist       0.00      0.00      0.00         0\n",
      "                           IT Vendor Manager       0.00      0.00      0.00         0\n",
      "                 IT Vendor Relations Manager       0.00      0.00      0.00         1\n",
      "                   Image Processing Engineer       0.00      0.00      0.00         0\n",
      "                   Incident Response Analyst       0.00      0.00      0.00         1\n",
      "                   Incident Response Manager       0.00      0.00      0.00         0\n",
      "              Industrial Automation Engineer       0.00      0.00      0.00         0\n",
      "            Information Assurance Specialist       0.00      0.00      0.00         0\n",
      "                Information Security Analyst       0.00      0.00      0.00         1\n",
      "                Information Security Manager       0.00      0.00      0.00         0\n",
      "                    Infrastructure Architect       0.00      0.00      0.00         0\n",
      "                     Infrastructure Engineer       0.00      0.00      0.00         0\n",
      "                          Innovation Manager       0.00      0.00      0.00         0\n",
      "                       Integration Architect       0.00      0.00      0.00         0\n",
      "                       Integration Developer       0.00      0.00      0.00         0\n",
      "                                IoT Engineer       0.00      0.00      0.00         0\n",
      "                       IoT Security Engineer       0.00      0.00      0.00         0\n",
      "                     IoT Solutions Architect       0.00      0.00      0.00         0\n",
      "                         Kubernetes Engineer       0.00      0.00      0.00         0\n",
      "                          Legal Technologist       0.00      0.00      0.00         0\n",
      "                   Machine Learning Engineer       0.00      0.00      0.00         0\n",
      "Machine Learning Operations (MLOps) Engineer       0.00      0.00      0.00         1\n",
      "        Machine Learning Operations Engineer       0.00      0.00      0.00         0\n",
      "         Machine Learning Research Scientist       0.00      0.00      0.00         1\n",
      "                             Malware Analyst       0.00      0.00      0.00         0\n",
      "                   Microcontroller Developer       0.00      0.00      0.00         1\n",
      "                         Middleware Engineer       0.00      0.00      0.00         0\n",
      "                        Mobile App Architect       0.00      0.00      0.00         1\n",
      "                        Mobile App Developer       0.10      0.04      0.06        24\n",
      "                Mobile Application Developer       0.00      0.00      0.00         0\n",
      "                    Mobile Security Engineer       0.00      0.00      0.00         1\n",
      "                         Mobile UI Developer       0.00      0.00      0.00         0\n",
      "                                NLP Engineer       0.00      0.00      0.00         1\n",
      "  Natural Language Processing (NLP) Engineer       0.00      0.00      0.00         1\n",
      " Natural Language Processing (NLP) Scientist       0.00      0.00      0.00         0\n",
      "                       Network Administrator       0.00      0.00      0.00         2\n",
      "                           Network Architect       0.00      0.00      0.00         1\n",
      "                            Network Engineer       0.00      0.00      0.00         1\n",
      "               Network Optimization Engineer       0.00      0.00      0.00         0\n",
      "                   Network Security Engineer       0.00      0.00      0.00         0\n",
      "                    Network Systems Engineer       0.00      0.00      0.00         0\n",
      "                          Penetration Tester       0.00      0.00      0.00         0\n",
      "                           Platform Engineer       0.00      0.00      0.00         0\n",
      "                  Platform Security Engineer       0.00      0.00      0.00         0\n",
      "             Predictive Analytics Specialist       0.00      0.00      0.00         0\n",
      "                            Product Designer       0.00      0.00      0.00         0\n",
      "                             Product Manager       0.00      0.00      0.00         0\n",
      "                   Product Security Engineer       0.00      0.00      0.00         0\n",
      "             Quality Assurance (QA) Engineer       0.00      0.00      0.00         0\n",
      "                        Quantitative Analyst       0.00      0.00      0.00         0\n",
      "                Quantum Computing Researcher       0.00      0.00      0.00         0\n",
      "           Quantum Machine Learning Engineer       0.00      0.00      0.00         0\n",
      "                        Reliability Engineer       0.00      0.00      0.00         0\n",
      "                           Research Engineer       0.00      0.00      0.00         1\n",
      "                  Research Software Engineer       0.00      0.00      0.00         1\n",
      "                     Risk Management Analyst       0.00      0.00      0.00         0\n",
      "  Robotic Process Automation (RPA) Developer       0.00      0.00      0.00         0\n",
      "                           Robotics Engineer       0.00      0.00      0.00         0\n",
      "                  Robotics Software Engineer       0.00      0.00      0.00         0\n",
      "                              SAP Consultant       0.00      0.00      0.00         0\n",
      "                            Security Analyst       0.00      0.00      0.00         0\n",
      "                          Security Architect       0.00      0.00      0.00         1\n",
      "                           Security Engineer       0.00      0.00      0.00         1\n",
      "    Security Operations Center (SOC) Analyst       0.00      0.00      0.00         0\n",
      "                Security Operations Engineer       0.00      0.00      0.00         0\n",
      "                 Security Operations Manager       0.00      0.00      0.00         0\n",
      "                 Security Software Developer       0.00      0.00      0.00         1\n",
      "                    Service Delivery Manager       0.00      0.00      0.00         0\n",
      "                  Signal Processing Engineer       0.00      0.00      0.00         0\n",
      "                   Site Reliability Engineer       0.00      0.00      0.00         0\n",
      "             Site Reliability Engineer (SRE)       0.00      0.00      0.00         0\n",
      "                          Software Architect       0.00      0.00      0.00         1\n",
      "                          Software Developer       0.00      0.00      0.00         0\n",
      "                   Software Development Lead       0.00      0.00      0.00         1\n",
      "                Software Development Manager       0.00      0.00      0.00         0\n",
      "                           Software Engineer       0.08      0.15      0.11        13\n",
      "                Software Engineering Manager       0.00      0.00      0.00         0\n",
      "               Software Integration Engineer       0.00      0.00      0.00         0\n",
      "                  Software Quality Assurance       0.00      0.00      0.00         1\n",
      "        Software Quality Assurance (QA) Lead       0.00      0.00      0.00         0\n",
      "                   Software Release Engineer       0.00      0.00      0.00         0\n",
      "                   Software Security Analyst       0.00      0.00      0.00         0\n",
      "                      Software Test Engineer       0.00      0.00      0.00         1\n",
      "                          Solution Architect       0.00      0.00      0.00         1\n",
      "                         Solutions Architect       0.00      0.00      0.00         1\n",
      "                          Solutions Engineer       0.00      0.00      0.00         1\n",
      "                            Storage Engineer       0.00      0.00      0.00         0\n",
      "                        System Administrator       0.00      0.00      0.00        18\n",
      "                      System Design Engineer       0.00      0.00      0.00         0\n",
      "                 System Integration Engineer       0.00      0.00      0.00         1\n",
      "                           System Integrator       0.00      0.00      0.00         0\n",
      "                System Monitoring Specialist       0.00      0.00      0.00         1\n",
      "                   System Operations Analyst       0.00      0.00      0.00         1\n",
      "                 System Performance Engineer       0.00      0.00      0.00         1\n",
      "                    System Security Engineer       0.00      0.00      0.00         1\n",
      "                       Systems Administrator       0.00      0.00      0.00         0\n",
      "                   Systems Analysis Engineer       0.00      0.00      0.00         1\n",
      "                             Systems Analyst       0.00      0.00      0.00         2\n",
      "                           Systems Architect       0.00      0.00      0.00         0\n",
      "                            Systems Engineer       0.00      0.00      0.00         0\n",
      "                 Systems Engineering Manager       0.00      0.00      0.00         0\n",
      "              Systems Integration Consultant       0.00      0.00      0.00         1\n",
      "                Systems Integration Engineer       0.00      0.00      0.00         1\n",
      "              Systems Integration Specialist       0.00      0.00      0.00         0\n",
      "                          Systems Programmer       0.00      0.00      0.00         0\n",
      "                   Technical Account Manager       0.00      0.00      0.00         1\n",
      "                   Technical Product Manager       0.00      0.00      0.00         1\n",
      "                   Technical Program Manager       0.00      0.00      0.00         0\n",
      "                  Technical Services Manager       0.00      0.00      0.00         0\n",
      "               Technical Solutions Architect       0.00      0.00      0.00         1\n",
      "                  Technical Support Engineer       0.00      0.00      0.00         0\n",
      "                Technical Support Specialist       0.00      0.00      0.00         0\n",
      "                            Technical Writer       0.00      0.00      0.00         1\n",
      "              Technology Adoption Specialist       0.00      0.00      0.00         0\n",
      "                 Telecommunications Engineer       0.00      0.00      0.00         0\n",
      "               Telecommunications Specialist       0.00      0.00      0.00         0\n",
      "                    Test Automation Engineer       0.00      0.00      0.00         0\n",
      "                 Threat Intelligence Analyst       0.00      0.00      0.00         0\n",
      "                                 UI Engineer       0.00      0.00      0.00         0\n",
      "                              UI/UX Designer       0.00      0.00      0.00         0\n",
      "                            UI/UX Researcher       0.00      0.00      0.00         0\n",
      "                                 UX Engineer       0.00      0.00      0.00         0\n",
      "                               UX Researcher       0.00      0.00      0.00         0\n",
      "                              UX/UI Designer       0.00      0.00      0.00         0\n",
      "               User Experience (UX) Designer       0.00      0.00      0.00         0\n",
      "             User Experience (UX) Researcher       0.00      0.00      0.00         0\n",
      "                User Interface (UI) Designer       0.00      0.00      0.00         0\n",
      "                        VLSI Design Engineer       0.00      0.00      0.00         0\n",
      "              Virtual Reality (VR) Developer       0.00      0.00      0.00         0\n",
      "                   Virtual Reality Developer       0.00      0.00      0.00         0\n",
      "                     Virtualization Engineer       0.00      0.00      0.00         1\n",
      "         Voice User Interface (VUI) Designer       0.00      0.00      0.00         1\n",
      "                   Web Application Developer       0.00      0.00      0.00         0\n",
      "                                Web Designer       0.00      0.00      0.00         0\n",
      "                               Web Developer       0.00      0.00      0.00         0\n",
      "                     Web Security Specialist       0.00      0.00      0.00         0\n",
      "\n",
      "                                   micro avg       0.06      0.06      0.06       314\n",
      "                                   macro avg       0.00      0.00      0.00       314\n",
      "                                weighted avg       0.06      0.06      0.06       314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajaya\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ajaya\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ajaya\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ajaya\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ajaya\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ajaya\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'output-removed.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert \"Yes\"/\"No\" to binary (1/0)\n",
    "data.replace({\"Yes\": 1, \"No\": 0}, inplace=True)\n",
    "\n",
    "# Encode the job titles as numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['Job Title'] = label_encoder.fit_transform(data['Job Title'])\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = data.drop(columns='Job Title')\n",
    "y = data['Job Title']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter=2000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_logistic:.4f}\")\n",
    "\n",
    "# Get class labels and ensure they match\n",
    "class_labels = label_encoder.classes_\n",
    "\n",
    "# Ensure that the classification report matches the labels in y\n",
    "print(classification_report(y_test, y_pred_logistic, labels=range(len(class_labels)), target_names=class_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bf4441e-934e-42b9-99e0-4d6c34a93b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Job Title Combined Skills\n",
      "0    Software Developer                \n",
      "1  Full Stack Developer                \n",
      "2     Backend Developer                \n",
      "3    Frontend Developer                \n",
      "4  Mobile App Developer                \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Use TF-IDF to convert skills to numerical vectors\u001b[39;00m\n\u001b[0;32m     29\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m---> 30\u001b[0m job_skill_matrix \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(job_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCombined Skills\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Simulate user data (replace this with actual user data if available)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m user_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser ID\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCI/CD Pipelines\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     56\u001b[0m })\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2133\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2128\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2129\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2130\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2131\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2132\u001b[0m )\n\u001b[1;32m-> 2133\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[0;32m   2134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2135\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1388\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1380\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1381\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1385\u001b[0m             )\n\u001b[0;32m   1386\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1391\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1294\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1296\u001b[0m         )\n\u001b[0;32m   1298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'output-removed.csv'  # Replace with actual file path\n",
    "job_data = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the columns are as you've described:\n",
    "# ['Job Title', 'Python', 'Java', 'C++', 'SQL', 'HTML', 'CSS', 'JavaScript', 'React', 'Git',\n",
    "#  'Agile', 'Machine Learning', 'Operating Systems', 'Version Control', 'Cloud Platforms',\n",
    "#  'Containerization', 'Data Structures & Algorithms', 'API Development', \n",
    "#  'Microservices Architecture', 'Cybersecurity', 'Big Data', 'CI/CD Pipelines']\n",
    "\n",
    "# Combine all skill columns into a single string\n",
    "skill_columns = ['Python', 'Java', 'C++', 'SQL', 'HTML', 'CSS', 'JavaScript', 'React', \n",
    "                 'Git', 'Agile', 'Machine Learning', 'Operating Systems', 'Version Control', \n",
    "                 'Cloud Platforms', 'Containerization', 'Data Structures & Algorithms', \n",
    "                 'API Development', 'Microservices Architecture', 'Cybersecurity', 'Big Data', \n",
    "                 'CI/CD Pipelines']\n",
    "\n",
    "# Combine skills into a single 'Combined Skills' column\n",
    "job_data['Combined Skills'] = job_data[skill_columns].apply(lambda x: ' '.join(x.index[x == 1]), axis=1)\n",
    "\n",
    "# Check the combined skills column\n",
    "print(job_data[['Job Title', 'Combined Skills']].head())\n",
    "\n",
    "# Use TF-IDF to convert skills to numerical vectors\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "job_skill_matrix = tfidf_vectorizer.fit_transform(job_data['Combined Skills'])\n",
    "\n",
    "# Simulate user data (replace this with actual user data if available)\n",
    "user_data = pd.DataFrame({\n",
    "    'User ID': [1, 2, 3],\n",
    "    'Python': [1, 0, 1],\n",
    "    'Java': [0, 1, 1],\n",
    "    'C++': [0, 0, 1],\n",
    "    'SQL': [1, 1, 1],\n",
    "    'HTML': [1, 0, 0],\n",
    "    'CSS': [1, 0, 0],\n",
    "    'JavaScript': [1, 0, 1],\n",
    "    'React': [1, 0, 1],\n",
    "    'Git': [1, 1, 1],\n",
    "    'Agile': [1, 1, 1],\n",
    "    'Machine Learning': [1, 0, 1],\n",
    "    'Operating Systems': [1, 1, 1],\n",
    "    'Version Control': [1, 1, 1],\n",
    "    'Cloud Platforms': [1, 0, 1],\n",
    "    'Containerization': [0, 0, 1],\n",
    "    'Data Structures & Algorithms': [1, 1, 1],\n",
    "    'API Development': [0, 1, 1],\n",
    "    'Microservices Architecture': [0, 1, 1],\n",
    "    'Cybersecurity': [0, 1, 1],\n",
    "    'Big Data': [0, 1, 1],\n",
    "    'CI/CD Pipelines': [1, 1, 1]\n",
    "})\n",
    "\n",
    "# Combine user skills into a single string similar to job data\n",
    "user_data['Combined Skills'] = user_data[skill_columns].apply(lambda x: ' '.join(x.index[x == 1]), axis=1)\n",
    "\n",
    "# Transform user skills using the same TF-IDF vectorizer\n",
    "user_skill_matrix = tfidf_vectorizer.transform(user_data['Combined Skills'])\n",
    "\n",
    "# Calculate cosine similarity between each user and each job\n",
    "similarity_matrix = cosine_similarity(user_skill_matrix, job_skill_matrix)\n",
    "\n",
    "# Get the best-matching job for each user based on similarity scores\n",
    "top_n = 3  # You can change this to return the top N jobs for each user\n",
    "for i, user in user_data.iterrows():\n",
    "    similarity_scores = similarity_matrix[i]\n",
    "    top_job_indices = similarity_scores.argsort()[-top_n:][::-1]  # Get indices of top N jobs\n",
    "    top_jobs = job_data.iloc[top_job_indices]['Job Title'].values  # Get job titles for those indices\n",
    "    \n",
    "    print(f\"Top {top_n} jobs for User {user['User ID']} (Skills: {user['Combined Skills']}):\")\n",
    "    for job in top_jobs:\n",
    "        print(f\"- {job}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2858673-23fc-47a8-b2ca-e8e3c39b1d60",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/output-removed.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the job dataset\u001b[39;00m\n\u001b[0;32m      6\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/data/output-removed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with actual file path\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m job_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Columns representing skills (assumed from your description)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m skill_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJava\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC++\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSQL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTML\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCSS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJavaScript\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReact\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     11\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAgile\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMachine Learning\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperating Systems\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVersion Control\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     12\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCloud Platforms\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContainerization\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData Structures & Algorithms\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     13\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPI Development\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMicroservices Architecture\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCybersecurity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBig Data\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     14\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCI/CD Pipelines\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/output-removed.csv'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9325320c-c19d-4b29-b439-529475392f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40b90825-5e4f-4994-bafb-80ed2e40f351",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Yes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 18\u001b[0m\n\u001b[0;32m     11\u001b[0m skill_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJava\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC++\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSQL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTML\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCSS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJavaScript\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReact\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     12\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAgile\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMachine Learning\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperating Systems\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVersion Control\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     13\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCloud Platforms\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContainerization\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData Structures & Algorithms\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     14\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPI Development\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMicroservices Architecture\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCybersecurity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBig Data\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     15\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCI/CD Pipelines\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Ensure skill columns are numerical (0 or 1), and fill missing values if necessary\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m job_data[skill_columns] \u001b[38;5;241m=\u001b[39m job_data[skill_columns]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Simulate user data (replace with real user data if available)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m user_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser ID\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCI/CD Pipelines\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     44\u001b[0m })\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    416\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    417\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    418\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    419\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    420\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:134\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Yes'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load the job dataset\n",
    "file_path = 'output-removed.csv'  # Update this with your actual file path\n",
    "job_data = pd.read_csv(file_path)\n",
    "\n",
    "# List of skills columns\n",
    "skill_columns = ['Python', 'Java', 'C++', 'SQL', 'HTML', 'CSS', 'JavaScript', 'React', \n",
    "                 'Git', 'Agile', 'Machine Learning', 'Operating Systems', 'Version Control', \n",
    "                 'Cloud Platforms', 'Containerization', 'Data Structures & Algorithms', \n",
    "                 'API Development', 'Microservices Architecture', 'Cybersecurity', 'Big Data', \n",
    "                 'CI/CD Pipelines']\n",
    "\n",
    "# Ensure skill columns are numerical (0 or 1), and fill missing values if necessary\n",
    "job_data[skill_columns] = job_data[skill_columns].fillna(0).astype(int)\n",
    "\n",
    "# Simulate user data (replace with real user data if available)\n",
    "user_data = pd.DataFrame({\n",
    "    'User ID': [1, 2, 3],\n",
    "    'Python': [1, 0, 1],\n",
    "    'Java': [0, 1, 1],\n",
    "    'C++': [0, 0, 1],\n",
    "    'SQL': [1, 1, 1],\n",
    "    'HTML': [1, 0, 0],\n",
    "    'CSS': [1, 0, 0],\n",
    "    'JavaScript': [1, 0, 1],\n",
    "    'React': [1, 0, 1],\n",
    "    'Git': [1, 1, 1],\n",
    "    'Agile': [1, 1, 1],\n",
    "    'Machine Learning': [1, 0, 1],\n",
    "    'Operating Systems': [1, 1, 1],\n",
    "    'Version Control': [1, 1, 1],\n",
    "    'Cloud Platforms': [1, 0, 1],\n",
    "    'Containerization': [0, 0, 1],\n",
    "    'Data Structures & Algorithms': [1, 1, 1],\n",
    "    'API Development': [0, 1, 1],\n",
    "    'Microservices Architecture': [0, 1, 1],\n",
    "    'Cybersecurity': [0, 1, 1],\n",
    "    'Big Data': [0, 1, 1],\n",
    "    'CI/CD Pipelines': [1, 1, 1]\n",
    "})\n",
    "\n",
    "# Combine job and user data to ensure we scale them together\n",
    "combined_data = pd.concat([job_data[skill_columns], user_data[skill_columns]])\n",
    "\n",
    "# Standardize the skill data for both jobs and users\n",
    "scaler = StandardScaler()\n",
    "combined_data_scaled = scaler.fit_transform(combined_data)\n",
    "\n",
    "# Split the scaled data back into job and user data\n",
    "job_data_scaled = combined_data_scaled[:len(job_data)]\n",
    "user_data_scaled = combined_data_scaled[len(job_data):]\n",
    "\n",
    "# Use K-Nearest Neighbors to find the top 5 matching jobs for each user\n",
    "knn = NearestNeighbors(n_neighbors=5, metric='cosine')  # Cosine similarity can be used here too\n",
    "knn.fit(job_data_scaled)\n",
    "\n",
    "# Predict the top 5 jobs for each user based on their skill set\n",
    "top_n = 5  # Number of top matches to retrieve\n",
    "\n",
    "for i, user in user_data.iterrows():\n",
    "    user_skills_scaled = user_data_scaled[i].reshape(1, -1)\n",
    "    distances, job_indices = knn.kneighbors(user_skills_scaled, n_neighbors=top_n)\n",
    "    \n",
    "    print(f\"Top {top_n} jobs for User {user['User ID']} (Skills: {user[skill_columns].values}):\")\n",
    "    for idx, dist in zip(job_indices[0], distances[0]):\n",
    "        print(f\"- {job_data.iloc[idx]['Job Title']} (Distance: {dist:.4f})\")\n",
    "\n",
    "# Calculate accuracy based on some ground truth (if available)\n",
    "user_true_jobs = {\n",
    "    1: 'Software Developer',  # User 1's correct job\n",
    "    2: 'Backend Developer',   # User 2's correct job\n",
    "    3: 'Data Analyst'         # User 3's correct job\n",
    "}\n",
    "\n",
    "correct_predictions = 0\n",
    "\n",
    "# Iterate through users and check if the correct job is in the top 5\n",
    "for i, user in user_data.iterrows():\n",
    "    user_skills_scaled = user_data_scaled[i].reshape(1, -1)\n",
    "    distances, job_indices = knn.kneighbors(user_skills_scaled, n_neighbors=top_n)\n",
    "    \n",
    "    top_jobs = job_data.iloc[job_indices[0]]['Job Title'].values\n",
    "    \n",
    "    # Check if the correct job is in the top 5 predicted jobs\n",
    "    true_job = user_true_jobs.get(user['User ID'])\n",
    "    if true_job in top_jobs:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate accuracy as percentage\n",
    "accuracy = (correct_predictions / len(user_data)) * 100\n",
    "print(f\"\\nAccuracy of job prediction using KNN: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "250b208e-08b4-4ef4-8a5a-9eb9eab7f979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python                          object\n",
      "Java                            object\n",
      "C++                             object\n",
      "SQL                             object\n",
      "HTML                            object\n",
      "CSS                             object\n",
      "JavaScript                      object\n",
      "React                           object\n",
      "Git                             object\n",
      "Agile                           object\n",
      "Machine Learning                object\n",
      "Operating Systems               object\n",
      "Version Control                 object\n",
      "Cloud Platforms                 object\n",
      "Containerization                object\n",
      "Data Structures & Algorithms    object\n",
      "API Development                 object\n",
      "Microservices Architecture      object\n",
      "Cybersecurity                   object\n",
      "Big Data                        object\n",
      "CI/CD Pipelines                 object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types of the skill columns\n",
    "print(job_data[skill_columns].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8622062-cc51-4497-8733-b4e6ea83d8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric values in column 'Python': ['Yes' 'No']\n",
      "Non-numeric values in column 'Java': ['Yes' 'No']\n",
      "Non-numeric values in column 'C++': ['Yes' 'No']\n",
      "Non-numeric values in column 'SQL': ['Yes' 'No']\n",
      "Non-numeric values in column 'HTML': ['Yes' 'No']\n",
      "Non-numeric values in column 'CSS': ['Yes' 'No']\n",
      "Non-numeric values in column 'JavaScript': ['Yes' 'No']\n",
      "Non-numeric values in column 'React': ['No' 'Yes']\n",
      "Non-numeric values in column 'Git': ['Yes' 'No']\n",
      "Non-numeric values in column 'Agile': ['Yes' 'No']\n",
      "Non-numeric values in column 'Machine Learning': ['No' 'Yes']\n",
      "Non-numeric values in column 'Operating Systems': ['Yes' 'No']\n",
      "Non-numeric values in column 'Version Control': ['Yes' 'No']\n",
      "Non-numeric values in column 'Cloud Platforms': ['No' 'Yes']\n",
      "Non-numeric values in column 'Containerization': ['Yes' 'No']\n",
      "Non-numeric values in column 'Data Structures & Algorithms': ['Yes' 'No']\n",
      "Non-numeric values in column 'API Development': ['Yes' 'No']\n",
      "Non-numeric values in column 'Microservices Architecture': ['No' 'Yes']\n",
      "Non-numeric values in column 'Cybersecurity': ['No' 'Yes']\n",
      "Non-numeric values in column 'Big Data': ['No' 'Yes']\n",
      "Non-numeric values in column 'CI/CD Pipelines': ['Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a function to identify non-numeric values\n",
    "def find_non_numeric_values(df, columns):\n",
    "    non_numeric_values = {}\n",
    "    for col in columns:\n",
    "        # Try to convert column values to numeric\n",
    "        pd_numeric = pd.to_numeric(df[col], errors='coerce')\n",
    "        # Find non-numeric values\n",
    "        non_numeric = df[col][df[col] != pd_numeric]\n",
    "        if not non_numeric.empty:\n",
    "            non_numeric_values[col] = non_numeric.unique()\n",
    "    return non_numeric_values\n",
    "\n",
    "# Apply the function\n",
    "non_numeric_values = find_non_numeric_values(job_data, skill_columns)\n",
    "\n",
    "# Print non-numeric values\n",
    "for col, values in non_numeric_values.items():\n",
    "    print(f\"Non-numeric values in column '{col}': {values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ece7bb68-b9b7-4289-ad93-80a438fe3652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python                          int64\n",
      "Java                            int64\n",
      "C++                             int64\n",
      "SQL                             int64\n",
      "HTML                            int64\n",
      "CSS                             int64\n",
      "JavaScript                      int64\n",
      "React                           int64\n",
      "Git                             int64\n",
      "Agile                           int64\n",
      "Machine Learning                int64\n",
      "Operating Systems               int64\n",
      "Version Control                 int64\n",
      "Cloud Platforms                 int64\n",
      "Containerization                int64\n",
      "Data Structures & Algorithms    int64\n",
      "API Development                 int64\n",
      "Microservices Architecture      int64\n",
      "Cybersecurity                   int64\n",
      "Big Data                        int64\n",
      "CI/CD Pipelines                 int64\n",
      "dtype: object\n",
      "   Python  Java  C++  SQL  HTML  CSS  JavaScript  React  Git  Agile  ...  \\\n",
      "0       1     1    1    1     1    1           1      0    1      1  ...   \n",
      "1       1     0    0    1     1    1           1      1    1      1  ...   \n",
      "2       1     1    0    1     0    0           0      0    1      1  ...   \n",
      "3       0     0    0    0     1    1           1      1    1      1  ...   \n",
      "4       1     1    1    0     0    0           0      0    1      1  ...   \n",
      "\n",
      "   Operating Systems  Version Control  Cloud Platforms  Containerization  \\\n",
      "0                  1                1                0                 1   \n",
      "1                  1                1                1                 1   \n",
      "2                  1                1                1                 1   \n",
      "3                  0                1                0                 0   \n",
      "4                  1                1                1                 0   \n",
      "\n",
      "   Data Structures & Algorithms  API Development  Microservices Architecture  \\\n",
      "0                             1                1                           0   \n",
      "1                             1                1                           1   \n",
      "2                             1                1                           1   \n",
      "3                             1                1                           0   \n",
      "4                             1                1                           1   \n",
      "\n",
      "   Cybersecurity  Big Data  CI/CD Pipelines  \n",
      "0              0         0                1  \n",
      "1              0         0                1  \n",
      "2              0         0                1  \n",
      "3              0         0                1  \n",
      "4              0         0                1  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Yes' to 1 and 'No' to 0 in skill columns\n",
    "job_data[skill_columns] = job_data[skill_columns].replace({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Verify the conversion\n",
    "print(job_data[skill_columns].dtypes)\n",
    "print(job_data[skill_columns].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bd1985a-83e9-4278-b26d-57acd38bd135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python                          int64\n",
      "Java                            int64\n",
      "C++                             int64\n",
      "SQL                             int64\n",
      "HTML                            int64\n",
      "CSS                             int64\n",
      "JavaScript                      int64\n",
      "React                           int64\n",
      "Git                             int64\n",
      "Agile                           int64\n",
      "Machine Learning                int64\n",
      "Operating Systems               int64\n",
      "Version Control                 int64\n",
      "Cloud Platforms                 int64\n",
      "Containerization                int64\n",
      "Data Structures & Algorithms    int64\n",
      "API Development                 int64\n",
      "Microservices Architecture      int64\n",
      "Cybersecurity                   int64\n",
      "Big Data                        int64\n",
      "CI/CD Pipelines                 int64\n",
      "dtype: object\n",
      "   Python  Java  C++  SQL  HTML  CSS  JavaScript  React  Git  Agile  ...  \\\n",
      "0       1     1    1    1     1    1           1      0    1      1  ...   \n",
      "1       1     0    0    1     1    1           1      1    1      1  ...   \n",
      "2       1     1    0    1     0    0           0      0    1      1  ...   \n",
      "3       0     0    0    0     1    1           1      1    1      1  ...   \n",
      "4       1     1    1    0     0    0           0      0    1      1  ...   \n",
      "\n",
      "   Operating Systems  Version Control  Cloud Platforms  Containerization  \\\n",
      "0                  1                1                0                 1   \n",
      "1                  1                1                1                 1   \n",
      "2                  1                1                1                 1   \n",
      "3                  0                1                0                 0   \n",
      "4                  1                1                1                 0   \n",
      "\n",
      "   Data Structures & Algorithms  API Development  Microservices Architecture  \\\n",
      "0                             1                1                           0   \n",
      "1                             1                1                           1   \n",
      "2                             1                1                           1   \n",
      "3                             1                1                           0   \n",
      "4                             1                1                           1   \n",
      "\n",
      "   Cybersecurity  Big Data  CI/CD Pipelines  \n",
      "0              0         0                1  \n",
      "1              0         0                1  \n",
      "2              0         0                1  \n",
      "3              0         0                1  \n",
      "4              0         0                1  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Top 5 jobs for User 1 (Skills: [1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1]):\n",
      "- Backend Developer (Distance: 0.2853)\n",
      "- Web Application Developer (Distance: 0.2997)\n",
      "- Frontend Developer (Distance: 0.2997)\n",
      "- Web Developer (Distance: 0.2997)\n",
      "- DevOps Engineer (Distance: 0.3705)\n",
      "Top 5 jobs for User 2 (Skills: [0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1]):\n",
      "- IT Security Director (Distance: 0.2547)\n",
      "- IT Security Manager (Distance: 0.2547)\n",
      "- Application Security Engineer (Distance: 0.3731)\n",
      "- DevSecOps Engineer (Distance: 0.3766)\n",
      "- IT Security Engineer (Distance: 0.3766)\n",
      "Top 5 jobs for User 3 (Skills: [1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]):\n",
      "- Technical Solutions Architect (Distance: 0.1099)\n",
      "- Enterprise Architect (Distance: 0.1099)\n",
      "- IT Security Architect (Distance: 0.2232)\n",
      "- Edge Computing Engineer (Distance: 0.2232)\n",
      "- Security Architect (Distance: 0.2289)\n",
      "\n",
      "Accuracy of job prediction using KNN: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load the job dataset\n",
    "file_path = 'output-removed.csv'  # Update this with your actual file path\n",
    "job_data = pd.read_csv(file_path)\n",
    "\n",
    "# List of skills columns\n",
    "skill_columns = ['Python', 'Java', 'C++', 'SQL', 'HTML', 'CSS', 'JavaScript', 'React', \n",
    "                 'Git', 'Agile', 'Machine Learning', 'Operating Systems', 'Version Control', \n",
    "                 'Cloud Platforms', 'Containerization', 'Data Structures & Algorithms', \n",
    "                 'API Development', 'Microservices Architecture', 'Cybersecurity', 'Big Data', \n",
    "                 'CI/CD Pipelines']\n",
    "\n",
    "# Convert 'Yes' to 1 and 'No' to 0 in skill columns\n",
    "job_data[skill_columns] = job_data[skill_columns].replace({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Verify the conversion\n",
    "print(job_data[skill_columns].dtypes)\n",
    "print(job_data[skill_columns].head())\n",
    "\n",
    "# Simulate user data (replace with real user data if available)\n",
    "user_data = pd.DataFrame({\n",
    "    'User ID': [1, 2, 3],\n",
    "    'Python': [1, 0, 1],\n",
    "    'Java': [0, 1, 1],\n",
    "    'C++': [0, 0, 1],\n",
    "    'SQL': [1, 1, 1],\n",
    "    'HTML': [1, 0, 0],\n",
    "    'CSS': [1, 0, 0],\n",
    "    'JavaScript': [1, 0, 1],\n",
    "    'React': [1, 0, 1],\n",
    "    'Git': [1, 1, 1],\n",
    "    'Agile': [1, 1, 1],\n",
    "    'Machine Learning': [1, 0, 1],\n",
    "    'Operating Systems': [1, 1, 1],\n",
    "    'Version Control': [1, 1, 1],\n",
    "    'Cloud Platforms': [1, 0, 1],\n",
    "    'Containerization': [0, 0, 1],\n",
    "    'Data Structures & Algorithms': [1, 1, 1],\n",
    "    'API Development': [0, 1, 1],\n",
    "    'Microservices Architecture': [0, 1, 1],\n",
    "    'Cybersecurity': [0, 1, 1],\n",
    "    'Big Data': [0, 1, 1],\n",
    "    'CI/CD Pipelines': [1, 1, 1]\n",
    "})\n",
    "\n",
    "# Combine job and user data to ensure we scale them together\n",
    "combined_data = pd.concat([job_data[skill_columns], user_data[skill_columns]])\n",
    "\n",
    "# Standardize the skill data for both jobs and users\n",
    "scaler = StandardScaler()\n",
    "combined_data_scaled = scaler.fit_transform(combined_data)\n",
    "\n",
    "# Split the scaled data back into job and user data\n",
    "job_data_scaled = combined_data_scaled[:len(job_data)]\n",
    "user_data_scaled = combined_data_scaled[len(job_data):]\n",
    "\n",
    "# Use K-Nearest Neighbors to find the top 5 matching jobs for each user\n",
    "knn = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
    "knn.fit(job_data_scaled)\n",
    "\n",
    "# Predict the top 5 jobs for each user based on their skill set\n",
    "top_n = 5  # Number of top matches to retrieve\n",
    "\n",
    "for i, user in user_data.iterrows():\n",
    "    user_skills_scaled = user_data_scaled[i].reshape(1, -1)\n",
    "    distances, job_indices = knn.kneighbors(user_skills_scaled, n_neighbors=top_n)\n",
    "    \n",
    "    print(f\"Top {top_n} jobs for User {user['User ID']} (Skills: {user[skill_columns].values}):\")\n",
    "    for idx, dist in zip(job_indices[0], distances[0]):\n",
    "        print(f\"- {job_data.iloc[idx]['Job Title']} (Distance: {dist:.4f})\")\n",
    "\n",
    "# Calculate accuracy based on some ground truth (if available)\n",
    "user_true_jobs = {\n",
    "    1: 'Software Developer',  # User 1's correct job\n",
    "    2: 'Backend Developer',   # User 2's correct job\n",
    "    3: 'Data Analyst'         # User 3's correct job\n",
    "}\n",
    "\n",
    "correct_predictions = 0\n",
    "\n",
    "# Iterate through users and check if the correct job is in the top 5\n",
    "for i, user in user_data.iterrows():\n",
    "    user_skills_scaled = user_data_scaled[i].reshape(1, -1)\n",
    "    distances, job_indices = knn.kneighbors(user_skills_scaled, n_neighbors=top_n)\n",
    "    \n",
    "    top_jobs = job_data.iloc[job_indices[0]]['Job Title'].values\n",
    "    \n",
    "    # Check if the correct job is in the top 5 predicted jobs\n",
    "    true_job = user_true_jobs.get(user['User ID'])\n",
    "    if true_job in top_jobs:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate accuracy as percentage\n",
    "accuracy = (correct_predictions / len(user_data)) * 100\n",
    "print(f\"\\nAccuracy of job prediction using KNN: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2846d049-d6cc-412c-8089-25d5377a6059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1 - Predicted Job: 22, True Job: Software Developer\n",
      "User 2 - Predicted Job: 230, True Job: Backend Developer\n",
      "User 3 - Predicted Job: 377, True Job: Data Analyst\n",
      "\n",
      "Accuracy of job prediction using Random Forest: 0.00%\n",
      "\n",
      "Job Titles in Dataset:\n",
      "Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
      "       ...\n",
      "       394, 395, 396, 397, 398, 399, 400, 401, 402, 403],\n",
      "      dtype='int16', length=404)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the job dataset\n",
    "file_path = 'output-removed.csv'  # Update this with your actual file path\n",
    "job_data = pd.read_csv(file_path)\n",
    "\n",
    "# List of skills columns\n",
    "skill_columns = ['Python', 'Java', 'C++', 'SQL', 'HTML', 'CSS', 'JavaScript', 'React', \n",
    "                 'Git', 'Agile', 'Machine Learning', 'Operating Systems', 'Version Control', \n",
    "                 'Cloud Platforms', 'Containerization', 'Data Structures & Algorithms', \n",
    "                 'API Development', 'Microservices Architecture', 'Cybersecurity', 'Big Data', \n",
    "                 'CI/CD Pipelines']\n",
    "\n",
    "# Convert non-numeric values to numeric\n",
    "for col in skill_columns:\n",
    "    if job_data[col].dtype == 'object':\n",
    "        job_data[col] = job_data[col].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Ensure there are no missing values and data is numeric\n",
    "job_data[skill_columns] = job_data[skill_columns].fillna(0).astype(int)\n",
    "\n",
    "# Encode the job titles\n",
    "job_data['Job Title'] = job_data['Job Title'].astype('category').cat.codes\n",
    "\n",
    "# Simulate user data (replace with real user data if available)\n",
    "user_data = pd.DataFrame({\n",
    "    'User ID': [1, 2, 3],\n",
    "    'Python': [1, 0, 1],\n",
    "    'Java': [0, 1, 1],\n",
    "    'C++': [0, 0, 1],\n",
    "    'SQL': [1, 1, 1],\n",
    "    'HTML': [1, 0, 0],\n",
    "    'CSS': [1, 0, 0],\n",
    "    'JavaScript': [1, 0, 1],\n",
    "    'React': [1, 0, 1],\n",
    "    'Git': [1, 1, 1],\n",
    "    'Agile': [1, 1, 1],\n",
    "    'Machine Learning': [1, 0, 1],\n",
    "    'Operating Systems': [1, 1, 1],\n",
    "    'Version Control': [1, 1, 1],\n",
    "    'Cloud Platforms': [1, 0, 1],\n",
    "    'Containerization': [0, 0, 1],\n",
    "    'Data Structures & Algorithms': [1, 1, 1],\n",
    "    'API Development': [0, 1, 1],\n",
    "    'Microservices Architecture': [0, 1, 1],\n",
    "    'Cybersecurity': [0, 1, 1],\n",
    "    'Big Data': [0, 1, 1],\n",
    "    'CI/CD Pipelines': [1, 1, 1]\n",
    "})\n",
    "\n",
    "# Drop 'User ID' column from user_data\n",
    "user_data_skills = user_data.drop(columns=['User ID'])\n",
    "\n",
    "# Combine job and user data to ensure we scale them together\n",
    "combined_data = pd.concat([job_data[skill_columns], user_data_skills])\n",
    "\n",
    "# Standardize the skill data for both jobs and users\n",
    "scaler = StandardScaler()\n",
    "combined_data_scaled = scaler.fit_transform(combined_data)\n",
    "\n",
    "# Split the scaled data back into job and user data\n",
    "job_data_scaled = combined_data_scaled[:len(job_data)]\n",
    "user_data_scaled = combined_data_scaled[len(job_data):]\n",
    "\n",
    "# Define the target variable and feature set for training\n",
    "X_train = job_data_scaled\n",
    "y_train = job_data['Job Title']\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the job titles for users\n",
    "user_predictions = rf_model.predict(user_data_scaled)\n",
    "\n",
    "# Decode the predicted job titles\n",
    "job_title_mapping = dict(enumerate(job_data['Job Title'].astype('category').cat.categories))\n",
    "user_predictions_titles = [job_title_mapping[pred] for pred in user_predictions]\n",
    "\n",
    "# Output results\n",
    "user_true_jobs = {\n",
    "    1: 'Software Developer',  # Ensure these match exactly with job titles in dataset\n",
    "    2: 'Backend Developer',\n",
    "    3: 'Data Analyst'\n",
    "}\n",
    "\n",
    "correct_predictions = 0\n",
    "\n",
    "for i, user in user_data.iterrows():\n",
    "    predicted_job = user_predictions_titles[i]\n",
    "    true_job = user_true_jobs.get(user['User ID'])\n",
    "    \n",
    "    print(f\"User {user['User ID']} - Predicted Job: {predicted_job}, True Job: {true_job}\")\n",
    "    \n",
    "    if predicted_job == true_job:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate accuracy as percentage\n",
    "accuracy = (correct_predictions / len(user_data)) * 100\n",
    "print(f\"\\nAccuracy of job prediction using Random Forest: {accuracy:.2f}%\")\n",
    "\n",
    "# Print job titles in dataset for reference\n",
    "print(\"\\nJob Titles in Dataset:\")\n",
    "print(job_data['Job Title'].astype('category').cat.categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a437b20e-e14f-4a8d-a23d-bf9b148f1892",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Yes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(recommended_jobs)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 71\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[27], line 59\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m skill_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJava\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC++\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSQL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTML\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCSS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJavaScript\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReact\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     53\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAgile\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMachine Learning\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperating Systems\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVersion Control\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     54\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCloud Platforms\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContainerization\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData Structures & Algorithms\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     55\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPI Development\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMicroservices Architecture\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCybersecurity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBig Data\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     56\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCI/CD Pipelines\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Load and prepare job data\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m job_data \u001b[38;5;241m=\u001b[39m load_and_prepare_data(file_path, skill_columns)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Example user skills\u001b[39;00m\n\u001b[0;32m     62\u001b[0m user_provided_skills \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPython\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJava\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSQL\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[27], line 17\u001b[0m, in \u001b[0;36mload_and_prepare_data\u001b[1;34m(file_path, skill_columns)\u001b[0m\n\u001b[0;32m     14\u001b[0m job_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput-removed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Ensure skill columns are numerical (0 or 1)\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m job_data[skill_columns] \u001b[38;5;241m=\u001b[39m job_data[skill_columns]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m job_data\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    416\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    417\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    418\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    419\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    420\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:134\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Yes'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def load_and_prepare_data(file_path, skill_columns):\n",
    "    \"\"\"\n",
    "    Load job data from a CSV file and prepare it by ensuring skill columns are numerical.\n",
    "\n",
    "    :param file_path: Path to the CSV file containing job data\n",
    "    :param skill_columns: List of skill column names\n",
    "    :return: DataFrame with prepared job data\n",
    "    \"\"\"\n",
    "    # Load the job dataset\n",
    "    job_data = pd.read_csv('output-removed.csv')\n",
    "    \n",
    "    # Ensure skill columns are numerical (0 or 1)\n",
    "    job_data[skill_columns] = job_data[skill_columns].fillna(0).astype(int)\n",
    "    \n",
    "    return job_data\n",
    "\n",
    "def recommend_jobs(user_skills, job_data, skill_columns, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend jobs based on user-provided skills.\n",
    "\n",
    "    :param user_skills: List of skills known by the user (e.g., ['Python', 'Java'])\n",
    "    :param job_data: DataFrame containing job skill requirements\n",
    "    :param skill_columns: List of skill column names in the job data\n",
    "    :param top_n: Number of top job recommendations to return\n",
    "    :return: DataFrame of recommended jobs\n",
    "    \"\"\"\n",
    "    # Create a skill vector for the user\n",
    "    user_skill_vector = np.zeros(len(skill_columns))\n",
    "    for skill in user_skills:\n",
    "        if skill in skill_columns:\n",
    "            user_skill_vector[skill_columns.index(skill)] = 1\n",
    "\n",
    "    # Compute cosine similarity between user skill vector and each job skill vector\n",
    "    job_skill_vectors = job_data[skill_columns].values\n",
    "    similarity_scores = cosine_similarity([user_skill_vector], job_skill_vectors).flatten()\n",
    "\n",
    "    # Add similarity scores to job data and sort by similarity\n",
    "    job_data['Similarity'] = similarity_scores\n",
    "    recommended_jobs = job_data.sort_values(by='Similarity', ascending=False).head(top_n)\n",
    "\n",
    "    return recommended_jobs[['Job Title', 'Similarity']]\n",
    "\n",
    "def main():\n",
    "    # File path to the CSV file\n",
    "    file_path = 'output-removed.csv'  # Update this with your actual file path\n",
    "\n",
    "    # List of skills columns\n",
    "    skill_columns = ['Python', 'Java', 'C++', 'SQL', 'HTML', 'CSS', 'JavaScript', 'React', \n",
    "                     'Git', 'Agile', 'Machine Learning', 'Operating Systems', 'Version Control', \n",
    "                     'Cloud Platforms', 'Containerization', 'Data Structures & Algorithms', \n",
    "                     'API Development', 'Microservices Architecture', 'Cybersecurity', 'Big Data', \n",
    "                     'CI/CD Pipelines']\n",
    "\n",
    "    # Load and prepare job data\n",
    "    job_data = load_and_prepare_data(file_path, skill_columns)\n",
    "\n",
    "    # Example user skills\n",
    "    user_provided_skills = ['Python', 'Java', 'SQL']\n",
    "\n",
    "    # Recommend jobs based on user-provided skills\n",
    "    recommended_jobs = recommend_jobs(user_provided_skills, job_data, skill_columns, top_n=5)\n",
    "\n",
    "    print(\"Recommended Jobs:\")\n",
    "    print(recommended_jobs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4625d468-1465-482e-a576-60f5f8942c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Jobs:\n",
      "                      Job Title  Similarity\n",
      "383  Data Governance Specialist    0.654654\n",
      "377            Technical Writer    0.654654\n",
      "423      IT Training Specialist    0.654654\n",
      "440      IT Performance Analyst    0.654654\n",
      "296          Systems Programmer    0.577350\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def load_and_prepare_data(file_path, skill_columns):\n",
    "    \"\"\"\n",
    "    Load job data from a CSV file and prepare it by ensuring skill columns are numerical.\n",
    "\n",
    "    :param file_path: Path to the CSV file containing job data\n",
    "    :param skill_columns: List of skill column names\n",
    "    :return: DataFrame with prepared job data\n",
    "    \"\"\"\n",
    "    # Load the job dataset\n",
    "    job_data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert non-numeric values to numeric\n",
    "    for column in skill_columns:\n",
    "        if column in job_data.columns:\n",
    "            job_data[column] = job_data[column].replace({'Yes': 1, 'No': 0})\n",
    "            job_data[column] = pd.to_numeric(job_data[column], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    return job_data\n",
    "\n",
    "def recommend_jobs(user_skills, job_data, skill_columns, top_n=5):\n",
    "    \"\"\"\n",
    "    Recommend jobs based on user-provided skills.\n",
    "\n",
    "    :param user_skills: List of skills known by the user (e.g., ['Python', 'Java'])\n",
    "    :param job_data: DataFrame containing job skill requirements\n",
    "    :param skill_columns: List of skill column names in the job data\n",
    "    :param top_n: Number of top job recommendations to return\n",
    "    :return: DataFrame of recommended jobs\n",
    "    \"\"\"\n",
    "    # Create a skill vector for the user\n",
    "    user_skill_vector = np.zeros(len(skill_columns))\n",
    "    for skill in user_skills:\n",
    "        if skill in skill_columns:\n",
    "            user_skill_vector[skill_columns.index(skill)] = 1\n",
    "\n",
    "    # Compute cosine similarity between user skill vector and each job skill vector\n",
    "    job_skill_vectors = job_data[skill_columns].values\n",
    "    similarity_scores = cosine_similarity([user_skill_vector], job_skill_vectors).flatten()\n",
    "\n",
    "    # Add similarity scores to job data and sort by similarity\n",
    "    job_data['Similarity'] = similarity_scores\n",
    "    recommended_jobs = job_data.sort_values(by='Similarity', ascending=False).head(top_n)\n",
    "\n",
    "    return recommended_jobs[['Job Title', 'Similarity']]\n",
    "\n",
    "def main():\n",
    "    # File path to the CSV file\n",
    "    file_path = 'output-removed.csv'  # Update this with your actual file path\n",
    "\n",
    "    # List of skills columns\n",
    "    skill_columns = ['Python', 'Java', 'C++', 'SQL', 'HTML', 'CSS', 'JavaScript', 'React', \n",
    "                     'Git', 'Agile', 'Machine Learning', 'Operating Systems', 'Version Control', \n",
    "                     'Cloud Platforms', 'Containerization', 'Data Structures & Algorithms', \n",
    "                     'API Development', 'Microservices Architecture', 'Cybersecurity', 'Big Data', \n",
    "                     'CI/CD Pipelines']\n",
    "\n",
    "    # Load and prepare job data\n",
    "    job_data = load_and_prepare_data(file_path, skill_columns)\n",
    "\n",
    "    # Example user skills\n",
    "    user_provided_skills = ['Python', 'Java', 'SQL']\n",
    "\n",
    "    # Recommend jobs based on user-provided skills\n",
    "    recommended_jobs = recommend_jobs(user_provided_skills, job_data, skill_columns, top_n=5)\n",
    "\n",
    "    print(\"Recommended Jobs:\")\n",
    "    print(recommended_jobs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85ab2975-9a9d-44fa-9173-b78aa12679d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 5.11%\n",
      "Recommended Job Categories: ['Backend Developer']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajaya\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load and prepare the data\n",
    "def load_and_prepare_data(file_path, skill_columns):\n",
    "    job_data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert non-numeric skill values like 'Yes'/'No' to 1/0\n",
    "    for col in skill_columns:\n",
    "        job_data[col] = job_data[col].map({'Yes': 1, 'No': 0, np.nan: 0})\n",
    "    \n",
    "    return job_data\n",
    "\n",
    "# Main function to handle skill matching and job recommendation\n",
    "def main():\n",
    "    file_path = 'output-removed.csv'  # Your dataset CSV file\n",
    "    skill_columns = ['Python', 'Java', 'C++', 'SQL', 'HTML', 'CSS', 'JavaScript', 'React',\n",
    "                     'Git', 'Agile', 'Machine Learning', 'Operating Systems', 'Version Control',\n",
    "                     'Cloud Platforms', 'Containerization', 'Data Structures & Algorithms',\n",
    "                     'API Development', 'Microservices Architecture', 'Cybersecurity', 'Big Data',\n",
    "                     'CI/CD Pipelines']\n",
    "\n",
    "    job_data = load_and_prepare_data(file_path, skill_columns)\n",
    "    \n",
    "    # Features and target\n",
    "    X = job_data[skill_columns]\n",
    "    y = job_data['Job Title']  # Use 'Job Title' as the target variable\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train a RandomForest Classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Example user input of skills\n",
    "    user_provided_skills = ['Python', 'Java', 'SQL']\n",
    "    \n",
    "    # Create a user skill vector (0s and 1s)\n",
    "    user_vector = [1 if skill in user_provided_skills else 0 for skill in skill_columns]\n",
    "    user_vector_scaled = scaler.transform([user_vector])\n",
    "    \n",
    "    # Recommend jobs based on user skills\n",
    "    recommended_jobs = model.predict(user_vector_scaled)\n",
    "    print(f\"Recommended Job Categories: {recommended_jobs}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c76aa9ff-3a70-4479-a718-22c6a7bff30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 5.11%\n",
      "Recommended Job Categories: ['Backend Developer']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load and prepare the data\n",
    "def load_and_prepare_data(file_path, skill_columns):\n",
    "    job_data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert non-numeric skill values like 'Yes'/'No' to 1/0\n",
    "    for col in skill_columns:\n",
    "        job_data[col] = job_data[col].map({'Yes': 1, 'No': 0, np.nan: 0})\n",
    "    \n",
    "    return job_data\n",
    "\n",
    "# Main function to handle skill matching and job recommendation\n",
    "def main():\n",
    "    file_path = 'output-removed.csv'  # Your dataset CSV file\n",
    "    skill_columns = ['Python', 'Java', 'C++', 'SQL', 'HTML', 'CSS', 'JavaScript', 'React',\n",
    "                     'Git', 'Agile', 'Machine Learning', 'Operating Systems', 'Version Control',\n",
    "                     'Cloud Platforms', 'Containerization', 'Data Structures & Algorithms',\n",
    "                     'API Development', 'Microservices Architecture', 'Cybersecurity', 'Big Data',\n",
    "                     'CI/CD Pipelines']\n",
    "\n",
    "    job_data = load_and_prepare_data(file_path, skill_columns)\n",
    "    \n",
    "    # Features and target\n",
    "    X = job_data[skill_columns]\n",
    "    y = job_data['Job Title']  # Use 'Job Title' as the target variable\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train a RandomForest Classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Example user input of skills\n",
    "    user_provided_skills = ['Python', 'Java', 'SQL']\n",
    "    \n",
    "    # Create a user skill vector as a DataFrame with column names\n",
    "    user_vector = pd.DataFrame([{\n",
    "        skill: 1 if skill in user_provided_skills else 0 for skill in skill_columns\n",
    "    }])\n",
    "    \n",
    "    # Standardize the user vector\n",
    "    user_vector_scaled = scaler.transform(user_vector)\n",
    "    \n",
    "    # Recommend jobs based on user skills\n",
    "    recommended_jobs = model.predict(user_vector_scaled)\n",
    "    print(f\"Recommended Job Categories: {recommended_jobs}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95d29560-24d5-4962-995d-59d620a4f999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajaya\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 4.47% with tuned RandomForest\n",
      "Recommended Job Categories: ['Backend Developer']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load and prepare the data\n",
    "def load_and_prepare_data(file_path, skill_columns):\n",
    "    job_data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert non-numeric skill values like 'Yes'/'No' to 1/0\n",
    "    for col in skill_columns:\n",
    "        job_data[col] = job_data[col].map({'Yes': 1, 'No': 0, np.nan: 0})\n",
    "    \n",
    "    return job_data\n",
    "\n",
    "# Main function to handle skill matching and job recommendation\n",
    "def main():\n",
    "    file_path = 'output-removed.csv'  # Your dataset CSV file\n",
    "    skill_columns = ['Python', 'Java', 'C++', 'SQL', 'HTML', 'CSS', 'JavaScript', 'React',\n",
    "                     'Git', 'Agile', 'Machine Learning', 'Operating Systems', 'Version Control',\n",
    "                     'Cloud Platforms', 'Containerization', 'Data Structures & Algorithms',\n",
    "                     'API Development', 'Microservices Architecture', 'Cybersecurity', 'Big Data',\n",
    "                     'CI/CD Pipelines']\n",
    "\n",
    "    job_data = load_and_prepare_data(file_path, skill_columns)\n",
    "    \n",
    "    # Features and target\n",
    "    X = job_data[skill_columns]\n",
    "    y = job_data['Job Title']  # Use 'Job Title' as the target variable\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Hyperparameter tuning for RandomForestClassifier\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Get the best model\n",
    "    best_rf = grid_search.best_estimator_\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy * 100:.2f}% with tuned RandomForest\")\n",
    "\n",
    "    # Example user input of skills\n",
    "    user_provided_skills = ['Python', 'Java', 'SQL']\n",
    "    \n",
    "    # Create a user skill vector as a DataFrame with column names\n",
    "    user_vector = pd.DataFrame([{\n",
    "        skill: 1 if skill in user_provided_skills else 0 for skill in skill_columns\n",
    "    }])\n",
    "    \n",
    "    # Standardize the user vector\n",
    "    user_vector_scaled = scaler.transform(user_vector)\n",
    "    \n",
    "    # Recommend jobs based on user skills\n",
    "    recommended_jobs = best_rf.predict(user_vector_scaled)\n",
    "    print(f\"Recommended Job Categories: {recommended_jobs}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecc9faf9-4098-43f6-9554-be128d05b343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajaya\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 10.53% with tuned RandomForest and StratifiedKFold\n",
      "Recommended Job Categories: ['Backend Developer']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load and prepare the job data\n",
    "def load_and_prepare_data(file_path, skill_columns):\n",
    "    job_data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert 'Yes'/'No' to 1/0 for skill columns\n",
    "    job_data[skill_columns] = job_data[skill_columns].replace({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    # Ensure skill columns are numerical (0 or 1)\n",
    "    job_data[skill_columns] = job_data[skill_columns].fillna(0).astype(int)\n",
    "    \n",
    "    # Remove job titles with fewer than a set number of occurrences (optional)\n",
    "    min_samples = 3\n",
    "    job_data = job_data.groupby('Job Title').filter(lambda x: len(x) >= min_samples)\n",
    "    \n",
    "    return job_data\n",
    "\n",
    "# Main function to handle skill matching and job recommendation\n",
    "def main():\n",
    "    file_path = 'output-removed.csv'  # Your dataset CSV file\n",
    "    skill_columns = ['Python', 'Java', 'C++', 'SQL', 'HTML', 'CSS', 'JavaScript', 'React',\n",
    "                     'Git', 'Agile', 'Machine Learning', 'Operating Systems', 'Version Control',\n",
    "                     'Cloud Platforms', 'Containerization', 'Data Structures & Algorithms',\n",
    "                     'API Development', 'Microservices Architecture', 'Cybersecurity', 'Big Data',\n",
    "                     'CI/CD Pipelines']\n",
    "\n",
    "    # Load the data\n",
    "    job_data = load_and_prepare_data(file_path, skill_columns)\n",
    "    \n",
    "    # Features and target\n",
    "    X = job_data[skill_columns]\n",
    "    y = job_data['Job Title']  # Use 'Job Title' as the target variable\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Hyperparameter tuning for RandomForestClassifier with StratifiedKFold\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    # Using StratifiedKFold to ensure balanced splits\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=skf, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Get the best model\n",
    "    best_rf = grid_search.best_estimator_\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy * 100:.2f}% with tuned RandomForest and StratifiedKFold\")\n",
    "\n",
    "    # Example user input of skills\n",
    "    user_provided_skills = ['Python', 'Java', 'SQL']\n",
    "    \n",
    "    # Create a user skill vector as a DataFrame with column names\n",
    "    user_vector = pd.DataFrame([{\n",
    "        skill: 1 if skill in user_provided_skills else 0 for skill in skill_columns\n",
    "    }])\n",
    "    \n",
    "    # Standardize the user vector\n",
    "    user_vector_scaled = scaler.transform(user_vector)\n",
    "    \n",
    "    # Recommend jobs based on user skills\n",
    "    recommended_jobs = best_rf.predict(user_vector_scaled)\n",
    "    print(f\"Recommended Job Categories: {recommended_jobs}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e7811-1235-4373-a904-389b2bb26563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
